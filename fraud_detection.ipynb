{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEtHJo2UNa0k"
      },
      "source": [
        "#  Import Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "7w-zcoDQ3o71",
        "outputId": "891d6089-8856-4a6c-9cf1-58221b362896"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'base (Python 3.10.14)' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -qO spark.tgz https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "!mkdir -p /content/spark\n",
        "!tar -xzf spark.tgz -C /content/spark --strip-components=1\n",
        "!pip install -q findspark pyspark==3.4.1 seaborn matplotlib pandas scikit-learn\n",
        "\n",
        "import os, findspark\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark\"\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()\n",
        "print(\"Spark started successfully!\")\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6a4e52c-f9f4-4249-9f5c-4cbd197a3865",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "rCNfx72v3mQm"
      },
      "source": [
        "# üöÄ Fraud Detection System\n",
        "### Machine Learning Pipeline for Transaction Fraud Detection\n",
        "\n",
        "**Features:**\n",
        "-  Class imbalance handling\n",
        "-  PCA dimensionality reduction\n",
        "-  Random Forest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "541a0f53-1fd1-4e05-9c4b-e3dfaba11e1e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ksrkqujz3mQo"
      },
      "source": [
        "## üìö 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1f65ef30-aab1-4284-918e-d56aab52762a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g2qoQGv3mQp",
        "outputId": "012b2234-f1de-4063-9d61-e709d92e2388"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, PCA\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8fac5840-3843-4acb-b9a7-42bf05c91278",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "QLRBvB6D3mQs"
      },
      "source": [
        "## üìÇ Load Transaction Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XdcziTOAccR",
        "outputId": "0bf2bcee-e487-40cb-8f7a-178b5d2c000a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5e8b088d-d0af-4cb0-8cff-a6e0bb9ca75c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ttQIf9ZX3mQt",
        "outputId": "e26d1336-28b1-441f-8cf3-a114320162df"
      },
      "outputs": [],
      "source": [
        "# Load CSV data\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/content/transactions_train.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Display dataset info\n",
        "row_count = df.count()\n",
        "col_count = len(df.columns)\n",
        "print(f\"Loaded dataset: {row_count:,} rows, {col_count} columns\")\n",
        "\n",
        "# Preview data\n",
        "display(df.limit(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f6850eb6-f4b9-4d3a-a3a2-ccd1a8b9b222",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "EqjhGSjW3mQt"
      },
      "source": [
        "## ‚öñÔ∏è Handle Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d3db460c-292a-402d-9836-8bc890a444b1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiys10aJ3mQt",
        "outputId": "b9a5819d-bc57-41bb-d3be-6d5339aaa645"
      },
      "outputs": [],
      "source": [
        "# Calculate class distribution\n",
        "count_0 = df.filter(col(\"isFraud\") == 0).count()\n",
        "count_1 = df.filter(col(\"isFraud\") == 1).count()\n",
        "imbalance_ratio = count_0 / count_1\n",
        "\n",
        "print(f\"Class Distribution:\")\n",
        "print(f\"  Normal transactions: {count_0:,}\")\n",
        "print(f\"  Fraud transactions: {count_1:,}\")\n",
        "print(f\"  Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "# Add class weights\n",
        "df = df.withColumn(\n",
        "    \"classWeight\",\n",
        "    when(col(\"isFraud\") == 1, imbalance_ratio).otherwise(1.0)\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Class weights added successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "89002a8d-ee57-434e-8b71-376f3aded932",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "eNcggx0h3mQu"
      },
      "source": [
        "## üîß Build ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a9153973-4fd6-43bd-b3b6-46a5ef88bc61",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtcmYBri3mQu",
        "outputId": "f4dc8393-4c4d-4137-d148-03a3bdc72863"
      },
      "outputs": [],
      "source": [
        "# Stage 1: String Indexer (convert categorical to numeric)\n",
        "indexer = StringIndexer() \\\n",
        "    .setInputCol(\"type\") \\\n",
        "    .setOutputCol(\"type_index\") \\\n",
        "    .setHandleInvalid(\"keep\")\n",
        "\n",
        "# Stage 2: One-Hot Encoder\n",
        "encoder = OneHotEncoder() \\\n",
        "    .setInputCols([\"type_index\"]) \\\n",
        "    .setOutputCols([\"type_encoded\"])\n",
        "\n",
        "# Stage 3: Vector Assembler (combine all features)\n",
        "feature_cols = [\n",
        "    \"step\",\n",
        "    \"amount\",\n",
        "    \"oldbalanceOrig\",\n",
        "    \"newbalanceOrig\",\n",
        "    \"oldbalanceDest\",\n",
        "    \"newbalanceDest\",\n",
        "    \"type_encoded\"\n",
        "]\n",
        "\n",
        "assembler = VectorAssembler() \\\n",
        "    .setInputCols(feature_cols) \\\n",
        "    .setOutputCol(\"features_raw\") \\\n",
        "    .setHandleInvalid(\"skip\")\n",
        "\n",
        "# Stage 4: PCA (dimensionality reduction)\n",
        "pca = PCA(k=5, inputCol=\"features_raw\", outputCol=\"features\")\n",
        "\n",
        "# Stage 5: Random Forest Classifier\n",
        "rf = RandomForestClassifier(\n",
        "    labelCol=\"isFraud\",\n",
        "    featuresCol=\"features\",\n",
        "    weightCol=\"classWeight\",\n",
        "    numTrees=100,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Combine all stages into pipeline\n",
        "pipeline = Pipeline(stages=[indexer, encoder, assembler, pca, rf])\n",
        "\n",
        "print(\"Pipeline built successfully\")\n",
        "print(f\"   Stages: {len(pipeline.getStages())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "646e5527-cfd1-4a70-97db-d36276be171f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "_JZIuGYn3mQw"
      },
      "source": [
        "## üîÄ Split Data (Train/Test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "eed18407-a15f-4e21-95fb-59f71f041227",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB5pDmfd3mQw",
        "outputId": "40d18f3e-4d80-461e-91f2-56775c638c4c"
      },
      "outputs": [],
      "source": [
        "# 70% training, 30% testing\n",
        "train_df, test_df = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "train_count = train_df.count()\n",
        "test_count = test_df.count()\n",
        "\n",
        "print(f\"Dataset Split:\")\n",
        "print(f\"  Training set: {train_count:,} rows ({train_count/row_count*100:.1f}%)\")\n",
        "print(f\"  Testing set: {test_count:,} rows ({test_count/row_count*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "61e05ed7-1d2a-472d-bc3f-6646fadca629",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "WcmQFX-K3mQw"
      },
      "source": [
        "## üéØ  Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1540769a-fa71-4f33-8e01-09810eb13d8b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pfueMcC3mQw",
        "outputId": "b5d91ae2-0660-44b4-aba6-f4439acbf874"
      },
      "outputs": [],
      "source": [
        "print(\"üöÄ Training Random Forest model...\")\n",
        "print(\"   This may take a few minutes...\")\n",
        "\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "print(\"Model trained successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "78abedcd-644f-4ade-9355-31b0f48284fd",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "uBYqTd-63mQw"
      },
      "source": [
        "##  Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "eae8e80a-bb45-42f1-a6d8-f5970e3a75c6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "kdVBHagL3mQx",
        "outputId": "5ec5edd1-293e-48c9-ad99-259c9fb80f0e"
      },
      "outputs": [],
      "source": [
        "# Transform test data\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Display sample predictions\n",
        "print(\"Sample Predictions:\")\n",
        "display(\n",
        "    predictions.select(\n",
        "        \"type\",\n",
        "        \"amount\",\n",
        "        \"isFraud\",\n",
        "        \"prediction\",\n",
        "        \"probability\"\n",
        "    ).limit(10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e62a3cb9-4cf0-44c2-ba78-88a8f8625eca",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Ltzfi_og3mQx"
      },
      "source": [
        "## Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "996bc657-51ec-4464-a299-c9dd5e3d584f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hphL78p53mQy",
        "outputId": "4cf9ac7b-9d4d-4678-bc67-a4b0dd2d275e"
      },
      "outputs": [],
      "source": [
        "# Initialize evaluators\n",
        "evaluator_roc = BinaryClassificationEvaluator(\n",
        "    labelCol=\"isFraud\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "\n",
        "evaluator_pr = BinaryClassificationEvaluator(\n",
        "    labelCol=\"isFraud\",\n",
        "    metricName=\"areaUnderPR\"\n",
        ")\n",
        "\n",
        "precision_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"isFraud\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"precisionByLabel\"\n",
        ")\n",
        "\n",
        "recall_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"isFraud\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"recallByLabel\"\n",
        ")\n",
        "\n",
        "f1_eval = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"isFraud\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"f1\"\n",
        ")\n",
        "\n",
        "# Calculate metrics\n",
        "auc_roc = evaluator_roc.evaluate(predictions)\n",
        "auc_pr = evaluator_pr.evaluate(predictions)\n",
        "precision = precision_eval.evaluate(predictions, {precision_eval.metricLabel: 1.0})\n",
        "recall = recall_eval.evaluate(predictions, {recall_eval.metricLabel: 1.0})\n",
        "f1 = f1_eval.evaluate(predictions)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 40)\n",
        "print(\"MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"AUC-ROC:   {auc_roc:.4f}\")\n",
        "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d180d59f-c9b1-4a5c-a338-6ce3e3dbdf65",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "isf2iuS53mQy"
      },
      "source": [
        "## üé® Confusion Matrix Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cbb2fed5-a870-4a38-9c89-0e45f0849d62",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "aHu1cH8O3mQy",
        "outputId": "9df6f776-2fcf-4bfb-b389-785523e7e6c4"
      },
      "outputs": [],
      "source": [
        "# Create confusion matrix (Serverless-safe method)\n",
        "conf_df = predictions \\\n",
        "    .groupBy(\"isFraud\", \"prediction\") \\\n",
        "    .count() \\\n",
        "    .toPandas() \\\n",
        "    .pivot(index=\"isFraud\", columns=\"prediction\", values=\"count\") \\\n",
        "    .fillna(0)\n",
        "\n",
        "# Format labels\n",
        "conf_df.columns = [\"Pred_Normal\", \"Pred_Fraud\"]\n",
        "conf_df.index = [\"Actual_Normal\", \"Actual_Fraud\"]\n",
        "\n",
        "print(\"\\nüìä Confusion Matrix:\")\n",
        "display(conf_df)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(\n",
        "    conf_df,\n",
        "    annot=True,\n",
        "    fmt=\".0f\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar_kws={'label': 'Count'}\n",
        ")\n",
        "plt.title(\"Confusion Matrix\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
        "plt.ylabel(\"Actual Label\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "display(plt.gcf())\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ff07db40-e054-4a7b-8adf-9a2117a81654",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "OCcRTjWg3mQz"
      },
      "source": [
        "## üîç  Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "930fd307-c8eb-4eb1-84a1-a66f94adf748",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "7uchkbnr3mQ0",
        "outputId": "2c5f89f7-3666-4572-bf21-79d1fa04a1c7"
      },
      "outputs": [],
      "source": [
        "# Extract Random Forest model\n",
        "rf_model = model.stages[-1]\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_model.featureImportances.toArray()\n",
        "\n",
        "# Create feature names (PCA components)\n",
        "feature_names = [f\"PCA_Component_{i+1}\" for i in range(len(importances))]\n",
        "\n",
        "# Create DataFrame\n",
        "importance_df = pd.DataFrame({\n",
        "    \"Feature\": feature_names,\n",
        "    \"Importance\": importances\n",
        "}).sort_values(\"Importance\", ascending=False)\n",
        "\n",
        "print(\"üîç Feature Importance (Top to Bottom):\")\n",
        "display(importance_df)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='steelblue')\n",
        "plt.xlabel(\"Importance Score\", fontsize=12)\n",
        "plt.ylabel(\"Feature\", fontsize=12)\n",
        "plt.title(\"Feature Importance Analysis\", fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "display(plt.gcf())\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3ba2cf7f-387a-4c63-a97b-a0050023faab",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "qum1k5Oa3mQ0"
      },
      "source": [
        "## üìã Final Summary 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0909d637-ac01-4adb-a2e2-4eecd094c76e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ3I_FKQ3mQ0",
        "outputId": "9f6f548d-1a2b-4031-f6cd-41fc313f15a2"
      },
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"üéâ FRAUD DETECTION - FINAL SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nüìä Dataset Information:\")\n",
        "print(f\"   Total rows: {row_count:,}\")\n",
        "print(f\"   Training set: {train_count:,}\")\n",
        "print(f\"   Testing set: {test_count:,}\")\n",
        "print(f\"\\n‚öñÔ∏è Class Balance:\")\n",
        "print(f\"   Normal: {count_0:,} | Fraud: {count_1:,}\")\n",
        "print(f\"   Ratio: {imbalance_ratio:.2f}:1\")\n",
        "print(f\"\\nüéØ Model Performance:\")\n",
        "print(f\"   AUC-ROC:   {auc_roc:.4f}\")\n",
        "print(f\"   AUC-PR:    {auc_pr:.4f}\")\n",
        "print(f\"   Precision: {precision:.4f}\")\n",
        "print(f\"   Recall:    {recall:.4f}\")\n",
        "print(f\"   F1-Score:  {f1:.4f}\")\n",
        "print(\"\\n‚úÖ Status: Completed successfully!\")\n",
        "print(\"‚úÖ Serverless: Compatible\")\n",
        "print(\"‚úÖ Whitelist: Safe\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzW9AVqJ8l3R"
      },
      "source": [
        "## Scikit-learn, Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKbOeqhI6SUV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi7T7RDtog3Y",
        "outputId": "537e6949-dbe1-4ffb-d164-7e5a3684f52b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r\"/content/drive/MyDrive/Colab Notebooks/content/transactions_train.csv\")\n",
        "\n",
        "# Create X,y\n",
        "X = df.drop(columns=['isFraud'])\n",
        "y = df['isFraud']\n",
        "\n",
        "# Label Encoding\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"Label Encoding ...\")\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "print(\"Label Encoding ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå\")\n",
        "\n",
        "\n",
        "#Undersampling\n",
        "print(\"\\nRandom Under-sampling...\")\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "print(\"Before undersampling:\\n\", y.value_counts())\n",
        "print(\"After undersampling:\\n\", pd.Series(y_resampled).value_counts())\n",
        "\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "print(f\"\\nSize Train Data: {X_train.shape[0]}\")\n",
        "print(f\"Size Test Data: {X_test.shape[0]}\")\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 ‡πÉ‡∏ä‡πâ CPU ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "\n",
        "print(\"\\nüöÄ Training Random Forest model...\")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predicted\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# model evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEQn7dewu6WW"
      },
      "source": [
        "## üìã Final Summary 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNHnRNrSrPZs",
        "outputId": "52ee2bdf-a963-4f82-d6a0-e7cd53ebe5ea"
      },
      "outputs": [],
      "source": [
        "# Model Evaluate\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n Dataset Information:\")\n",
        "print(f\" ¬† Precision: {precision:.4f}\")\n",
        "print(f\" ¬† Recall: ¬† ¬†{recall:.4f}\")\n",
        "print(f\" ¬† F1-Score: ¬†{f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QNK8uStqG8i"
      },
      "source": [
        "## üé® Confusion Matrix Visualization (Undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "jnItUahop-Qo",
        "outputId": "8a10b151-34bc-48e1-f9c0-c65f3766fa6d"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = [\"Normal\", \"Fraud\"]\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=labels, yticklabels=labels,\n",
        "            linewidths=0.5, linecolor=\"gray\", cbar=False)\n",
        "plt.title(\"Confusion Matrix (Undersampling + Random Forest)\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96M85PZQwpUP"
      },
      "source": [
        "## Comparison 1 & 2\n",
        "1. Pyspark + Ransom Forest + Class weight\n",
        "2. Scikit-learn + Random Forest + Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1swR80fm7ipH"
      },
      "outputs": [],
      "source": [
        "üéØ Model Performance:\n",
        "   AUC-ROC:   0.9938\n",
        "   AUC-PR:    0.6336\n",
        "   Precision: 0.0284\n",
        "   Recall:    0.9579\n",
        "   F1-Score:  0.9782"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "byDoDhf2wlIJ",
        "outputId": "d895b7d9-1aa3-46cc-9c4c-02a50e8073ec"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "methods = ['PySpark\\n(Class Weight)', 'Scikit-learn\\n(Undersampling)']\n",
        "\n",
        "\n",
        "metrics_data = {\n",
        "    'Metric': ['AUC-ROC', 'AUC-PR', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'PySpark': [0.9938, 0.6336, 0.0284, 0.9579, 0.9782],\n",
        "    'Scikit-learn': [None, None, 0.9878, 0.9981,  0.9929]\n",
        "}\n",
        "\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "fig.suptitle('PySpark (Class Weight) vs Scikit-learn (Undersampling)',\n",
        "             fontsize=24, fontweight='bold', y=0.98)\n",
        "\n",
        "\n",
        "ax1 = plt.subplot(3, 3, (1, 2))\n",
        "ax1.axis('tight')\n",
        "ax1.axis('off')\n",
        "\n",
        "table_data = [\n",
        "    ['Metric', 'PySpark\\n(Class Weight)', 'Scikit-learn\\n(Undersampling)', 'Winner'],\n",
        "    ['AUC-ROC', '0.9915', 'N/A', 'PySpark'],\n",
        "    ['AUC-PR', '0.6729', 'N/A', 'PySpark'],\n",
        "    ['Precision', '0.0284 (2.84%)', '0.9878 (98.78%)', 'Scikit-learn ‚úì'],\n",
        "    ['Recall', '0.9579 (95.79%)', '0.9981 (99.81%)', 'Scikit-learn ‚úì'],\n",
        "    ['F1-Score', '0.9782', '0.9929', 'Scikit-learn ‚úì']\n",
        "]\n",
        "\n",
        "colors = [['#1e3c72']*4]  # Header\n",
        "colors += [['white', '#fff3cd', '#d4edda', '#d1ecf1']] * 5  # Data rows\n",
        "\n",
        "table = ax1.table(cellText=table_data, cellLoc='center', loc='center',\n",
        "                  cellColours=colors, bbox=[0, 0, 1, 1])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(11)\n",
        "table.scale(1, 3)\n",
        "\n",
        "# Color & style\n",
        "for i in range(len(table_data)):\n",
        "    for j in range(len(table_data[0])):\n",
        "        cell = table[(i, j)]\n",
        "        if i == 0:  # Header\n",
        "            cell.set_text_props(weight='bold', color='white', size=12)\n",
        "            cell.set_facecolor('#1e3c72')\n",
        "        else:\n",
        "            if j == 0:  # Metric names\n",
        "                cell.set_text_props(weight='bold', size=11)\n",
        "            elif j == 3:  # Winner column\n",
        "                cell.set_text_props(weight='bold', size=10)\n",
        "        cell.set_edgecolor('#cccccc')\n",
        "        cell.set_linewidth(1.5)\n",
        "\n",
        "ax1.set_title('Evaluation Compare', fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "# Precision, Recall\n",
        "ax2 = plt.subplot(3, 3, 3)\n",
        "metrics_compare = ['Precision', 'Recall', 'F1-Score']\n",
        "pyspark_values = [0.0284, 0.9579, 0.9782]\n",
        "sklearn_values = [0.9878, 0.9981, 0.9929]\n",
        "\n",
        "x = np.arange(len(metrics_compare))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax2.bar(x - width/2, pyspark_values, width, label='PySpark',\n",
        "                color='#3498db', alpha=0.8, edgecolor='black')\n",
        "bars2 = ax2.bar(x + width/2, sklearn_values, width, label='Scikit-learn',\n",
        "                color='#2ecc71', alpha=0.8, edgecolor='black')\n",
        "\n",
        "ax2.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Compare Precision, Recall, F1-Score', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(metrics_compare, fontsize=10)\n",
        "ax2.set_ylim(0, 1.1)\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                f'{height:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "\n",
        "\n",
        "# Data Distribution - PySpark\n",
        "ax5 = plt.subplot(3, 3, 6)\n",
        "data_pyspark = [6343476, 7717]\n",
        "labels_data = ['Normal\\n6,343,476', 'Fraud\\n7,717']\n",
        "colors_pie = ['#3498db', '#e74c3c']\n",
        "explode = (0, 0.1)\n",
        "\n",
        "wedges, texts, autotexts = ax5.pie(data_pyspark, labels=labels_data, autopct='%1.2f%%',\n",
        "                                     startangle=90, colors=colors_pie, explode=explode,\n",
        "                                     textprops={'fontsize': 10, 'weight': 'bold'})\n",
        "ax5.set_title('PySpark: Ratio (822:1)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Data Distribution - Scikit-learn\n",
        "ax6 = plt.subplot(3, 3, 7)\n",
        "data_sklearn = [7717, 7717]  # After undersampling\n",
        "labels_sklearn = ['Normal\\n7,717', 'Fraud\\n7,717']\n",
        "colors_pie2 = ['#2ecc71', '#e74c3c']\n",
        "\n",
        "wedges2, texts2, autotexts2 = ax6.pie(data_sklearn, labels=labels_sklearn, autopct='%1.1f%%',\n",
        "                                        startangle=90, colors=colors_pie2,\n",
        "                                        textprops={'fontsize': 10, 'weight': 'bold'})\n",
        "ax6.set_title('Scikit-learn: Undersampled (1:1)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Training Data Size\n",
        "ax7 = plt.subplot(3, 3, 8)\n",
        "train_sizes = [4445579, 15434]  # PySpark full vs Sklearn after undersampling\n",
        "method_names = ['PySpark\\n(4.4M rows)', 'Scikit-learn\\n(15K rows)']\n",
        "bars = ax7.barh(method_names, train_sizes, color=['#3498db', '#2ecc71'],\n",
        "                edgecolor='black', linewidth=2)\n",
        "ax7.set_xlabel('Training Data Size (rows)', fontsize=12, fontweight='bold')\n",
        "ax7.set_title('Size Training Data', fontsize=14, fontweight='bold')\n",
        "ax7.set_xscale('log')\n",
        "ax7.grid(axis='x', alpha=0.3)\n",
        "\n",
        "for i, (bar, size) in enumerate(zip(bars, train_sizes)):\n",
        "    ax7.text(size * 1.2, i, f'{size:,}', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "#  False Positive Comparison\n",
        "ax8 = plt.subplot(3, 3, 9)\n",
        "fp_data = [54794, 1]  # False Positives\n",
        "method_names_fp = ['PySpark', 'Scikit-learn']\n",
        "bars_fp = ax8.bar(method_names_fp, fp_data, color=['#e74c3c', '#2ecc71'],\n",
        "                  edgecolor='black', linewidth=2, alpha=0.8)\n",
        "ax8.set_ylabel('False Positives', fontsize=12, fontweight='bold')\n",
        "ax8.set_title('Compare False Positive', fontsize=14, fontweight='bold')\n",
        "ax8.set_yscale('log')\n",
        "ax8.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar, fp in zip(bars_fp, fp_data):\n",
        "    height = bar.get_height()\n",
        "    ax8.text(bar.get_x() + bar.get_width()/2., height * 1.5,\n",
        "            f'{fp:,}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('fraud_detection_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGJkeJB3tWNo"
      },
      "source": [
        "## Another Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7rWTEJfrxrz"
      },
      "outputs": [],
      "source": [
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['figure.figsize'] = (6,4)\n",
        "plt.rcParams['axes.labelcolor'] = \"#002B5B\"\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.titleweight'] = \"bold\"\n",
        "plt.rcParams['axes.titlecolor'] = \"#002B5B\"\n",
        "plt.rcParams['axes.edgecolor'] = \"#A0A0A0\"\n",
        "plt.rcParams['axes.linewidth'] = 1.0\n",
        "\n",
        "# Dummy data for visualization\n",
        "train_size = 0.7\n",
        "test_size = 0.3\n",
        "normal_count = 6_343_476\n",
        "fraud_count = 7_717\n",
        "metrics = {\n",
        "    'AUC-ROC': 0.9915,\n",
        "    'AUC-PR': 0.6729,\n",
        "    'Precision': 0.0379,\n",
        "    'Recall': 0.9200,\n",
        "    'F1-Score': 0.9842\n",
        "}\n",
        "conf_matrix = np.array([[1848471, 54794],\n",
        "                        [188, 2161]])\n",
        "feature_importance = {\n",
        "    'PCA_Component_1': 0.05,\n",
        "    'PCA_Component_2': 0.10,\n",
        "    'PCA_Component_3': 0.08,\n",
        "    'PCA_Component_4': 0.13,\n",
        "    'PCA_Component_5': 0.64\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "xfvRR5zxEcLE",
        "outputId": "95232f4e-b428-4ebe-b207-655a39d89d7d"
      },
      "outputs": [],
      "source": [
        "labels = ['Train (70%)', 'Test (30%)']\n",
        "sizes = [train_size, test_size]\n",
        "colors = ['#004C99', '#A7C7E7']\n",
        "\n",
        "plt.figure()\n",
        "plt.pie(sizes, labels=labels, autopct='%1.0f%%', startangle=90, colors=colors, textprops={'color':'#002B5B'})\n",
        "plt.title(\"Data Split: Train vs Test\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "bHoAsRooEeup",
        "outputId": "ab004c44-6d36-4bbc-9f33-88263ac7f531"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.bar(['Normal', 'Fraud'], [normal_count, fraud_count], color=['#1F77B4','#B22222'])\n",
        "plt.yscale('log')\n",
        "plt.ylabel('Transaction Count (log scale)')\n",
        "plt.title(\"Data Imbalance: Normal vs Fraud\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "3KtIm69yEqjs",
        "outputId": "f0849c34-52b8-42a4-e561-59fec7b5b8be"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "names, values = zip(*metrics.items())\n",
        "sns.barplot(x=list(names), y=list(values), palette=\"Blues_d\")\n",
        "plt.title(\"Model Performance Metrics\")\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel(\"Score\")\n",
        "for i,v in enumerate(values):\n",
        "    plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', color='#002B5B', fontweight='bold')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": null,
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "fraud_detection_complete",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
